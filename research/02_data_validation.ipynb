{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f:\\\\OneDrive - MSFT\\\\wine_quality_ML\\\\Machine-Learning-End-to-End-Project\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f:\\\\OneDrive - MSFT\\\\wine_quality_ML\\\\Machine-Learning-End-to-End-Project'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataValidationConfig:\n",
    "    root_dir: Path\n",
    "    STATUS_FILE: str\n",
    "    unzip_data_dir: Path\n",
    "    all_schema: dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration Manager\n",
    "from src.MLProject_WineQT.constants.const import *\n",
    "from src.MLProject_WineQT.utils.common import read_yaml, create_directories\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(self, \n",
    "                 config_filepath=CONFIG_FILE_PATH,\n",
    "                 params_filepath=PARAMS_FILE_PATH,\n",
    "                 schema_filepath=SCHEMA_FILE_PATH):\n",
    "        \n",
    "        # Load config, params, and schema YAML files\n",
    "        self.config = read_yaml(config_filepath)  # Ensure this loads the YAML correctly\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        self.schema = read_yaml(schema_filepath)\n",
    "        \n",
    "        # Debugging: Print loaded config, params, and schema\n",
    "        print(f\"Loaded config: {self.config}\")\n",
    "        print(f\"Loaded params: {self.params}\")\n",
    "        print(f\"Loaded schema: {self.schema}\")\n",
    "\n",
    "        # Create directories specified in the config\n",
    "        create_directories([self.config.artifacts_root])\n",
    "    \n",
    "    def get_data_validation_config(self) -> DataValidationConfig:\n",
    "        config = self.config.data_validation  # Access 'data_validation' config block\n",
    "        \n",
    "        # Fetch the schema (columns) from the schema file\n",
    "        schema = self.schema.COLUMNS\n",
    "        create_directories([config.root_dir]) # Debug print to ensure schema is loaded\n",
    "        \n",
    "        data_validation_config=DataValidationConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            STATUS_FILE=config.STATUS_FILE,\n",
    "            unzip_data_dir=config.unzip_data_dir,\n",
    "            all_schema=schema\n",
    "        )\n",
    "        return data_validation_config\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "class DataValidation:\n",
    "    def __init__(self, config: DataValidationConfig):\n",
    "        self.config = config\n",
    "    \n",
    "    def validation_all_columns(self) -> bool:\n",
    "        try:\n",
    "            validation_status = None\n",
    "            data=pd.read_csv(self.config.unzip_data_dir)\n",
    "            all_cols= list(data.columns)\n",
    "            all_schema = self.config.all_schema.keys()\n",
    "           \n",
    "\n",
    "           \n",
    "\n",
    "            for col in all_cols:\n",
    "                if col not in all_schema:\n",
    "                    validation_status=False\n",
    "                    with open(self.config.STATUS_FILE,'w') as file:\n",
    "                    \n",
    "                        file.write(f'data validation status {validation_status}')\n",
    "                else:\n",
    "                    validation_status=True\n",
    "                    with open(self.config.STATUS_FILE,'w') as file:\n",
    "                    \n",
    "                        file.write(f'data validation status {validation_status}')\n",
    "            return validation_status\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "                    \n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-10-05 03:59:37,097: INFO: common: yaml file:config\\config.yaml load successfuly]\n",
      "[2024-10-05 03:59:37,101: INFO: common: yaml file:params.yaml load successfuly]\n",
      "[2024-10-05 03:59:37,112: INFO: common: yaml file:schema.yaml load successfuly]\n",
      "Loaded config: {'artifacts_root': 'artifacts', 'data_ingestion': {'root_dir': 'artifacts/data_ingestion', 'source_URL': 'https://github.com/AliTheAnalyst01/Machine-Learning-End-to-End-Project/raw/refs/heads/main/WineQT.zip', 'local_data_file': 'artifacts/data_ingestion/data.zip', 'unzip_dir': 'artifacts/data_ingestion/unzipped_data'}, 'data_validation': {'root_dir': 'artifacts/data_validation', 'STATUS_FILE': 'artifacts/data_validation/status.txt', 'unzip_data_dir': 'artifacts/data_ingestion/unzipped_data/WineQT.csv'}}\n",
      "Loaded params: {'key': 'val'}\n",
      "Loaded schema: {'COLUMNS': {'fixed acidity': 'float64', 'volatile acidity': 'float64', 'citric acid': 'float64', 'residual sugar': 'float64', 'chlorides': 'float64', 'free sulfur dioxide': 'float64', 'total sulfur dioxide': 'float64', 'density': 'float64', 'pH': 'float64', 'sulphates': 'float64', 'alcohol': 'float64', 'quality': 'int64', 'Id': 'int64'}, 'TARGET_COLUMN': {'name': 'quality'}}\n",
      "[2024-10-05 03:59:37,117: INFO: common: created directories at: artifacts]\n",
      "[2024-10-05 03:59:37,120: INFO: common: created directories at: artifacts/data_validation]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Initialize the configuration manager\n",
    "    config = ConfigurationManager()  \n",
    "    \n",
    "    # Fetch data validation configuration\n",
    "    data_validation_config = config.get_data_validation_config()\n",
    "    \n",
    "    # Create a DataValidation instance\n",
    "    data_validation = DataValidation(config=data_validation_config)\n",
    "    \n",
    "    # Perform the column validation\n",
    "    data_validation.validation_all_columns()\n",
    "except Exception as e:\n",
    "    raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: [Errno 2] No such file or directory: 'path/to/config.yaml'\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import os\n",
    "import yaml  # Assuming you're using PyYAML for reading YAML files\n",
    "\n",
    "# Define constants for file paths\n",
    "#CONFIG_FILE_PATH = 'path/to/config.yaml'  # Adjust the path as necessary\n",
    "#PARAMS_FILE_PATH = 'path/to/params.yaml'  # Adjust the path as necessary\n",
    "#SCHEMA_FILE_PATH = 'path/to/schema.yaml'  # Adjust the path as necessary\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataValidationConfig:\n",
    "    root_dir: Path\n",
    "    STATUS_FILE: str\n",
    "    all_schema: dict\n",
    "    unzip_data_dir: Path\n",
    "\n",
    "def read_yaml(file_path: str):\n",
    "    \"\"\"Read a YAML file and return its content.\"\"\"\n",
    "    with open(file_path, 'r') as file:\n",
    "        return yaml.safe_load(file)\n",
    "\n",
    "def create_directories(dirs: list):\n",
    "    \"\"\"Create directories if they do not exist.\"\"\"\n",
    "    for dir in dirs:\n",
    "        Path(dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "class ConfigurationManager:\n",
    "    def __init__(self, \n",
    "                 config_filepath=CONFIG_FILE_PATH,\n",
    "                 params_filepath=PARAMS_FILE_PATH,\n",
    "                 schema_filepath=SCHEMA_FILE_PATH):\n",
    "        \n",
    "        # Load config, params, and schema YAML files\n",
    "        self.config = read_yaml(config_filepath)  # Load the config file\n",
    "        self.params = read_yaml(params_filepath)  # Load the parameters file\n",
    "        self.schema = read_yaml(schema_filepath)  # Load the schema file\n",
    "        \n",
    "        # Debugging: Print loaded config, params, and schema\n",
    "        print(f\"Loaded config: {self.config}\")\n",
    "        print(f\"Loaded params: {self.params}\")\n",
    "        print(f\"Loaded schema: {self.schema}\")\n",
    "\n",
    "        # Create directories specified in the config\n",
    "        create_directories([self.config['artifacts_root']])\n",
    "    \n",
    "    def get_data_validation_config(self) -> DataValidationConfig:\n",
    "        config = self.config['data_validation']  # Access 'data_validation' config block\n",
    "        \n",
    "        # Fetch the schema (columns) from the schema file\n",
    "        schema = self.schema.get('COLUMNS', None)\n",
    "        print(f\"Loaded schema for validation: {schema}\")  # Debug print to ensure schema is loaded\n",
    "        \n",
    "        # Raise error if schema is not defined\n",
    "        if schema is None:\n",
    "            raise ValueError(\"Schema (COLUMNS) is not defined in the schema file.\")\n",
    "        \n",
    "        # Create directories for data validation\n",
    "        create_directories([config['root_dir']])\n",
    "        \n",
    "        # Create and return the DataValidationConfig instance\n",
    "        data_validation_config = DataValidationConfig(\n",
    "            root_dir=Path(config['root_dir']),\n",
    "            STATUS_FILE=config['STATUS_FILE'],\n",
    "            unzip_data_dir=Path(config['unzip_data_dir']),\n",
    "            all_schema=schema  # Use the loaded schema\n",
    "        )\n",
    "        \n",
    "        return data_validation_config\n",
    "\n",
    "class DataValidation:\n",
    "    def __init__(self, config: DataValidationConfig):\n",
    "        self.config = config\n",
    "    \n",
    "    def validation_all_columns(self) -> bool:\n",
    "        try:\n",
    "            validation_status = True  # Default to True\n",
    "            \n",
    "            # Check if the file exists\n",
    "            if not os.path.exists(self.config.unzip_data_dir):\n",
    "                raise FileNotFoundError(f\"File {self.config.unzip_data_dir} does not exist.\")\n",
    "            \n",
    "            # Read the CSV file from the specified directory\n",
    "            data = pd.read_csv(self.config.unzip_data_dir)  # Ensure this is the full file path\n",
    "            all_cols = list(data.columns)\n",
    "            \n",
    "            # Schema keys\n",
    "            all_schema = self.config.all_schema.keys()\n",
    "            \n",
    "            # Validate each column\n",
    "            for col in all_cols:\n",
    "                if col not in all_schema:\n",
    "                    validation_status = False\n",
    "                    with open(self.config.STATUS_FILE, 'w') as f:\n",
    "                        f.write(f\"Validation failed for column: {col}\\n\")\n",
    "                else:\n",
    "                    with open(self.config.STATUS_FILE, 'a') as f:  # Append mode\n",
    "                        f.write(f\"Validation passed for column: {col}\\n\")\n",
    "            \n",
    "            return validation_status\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred during validation: {e}\")\n",
    "            raise e\n",
    "\n",
    "# Example usage\n",
    "try:\n",
    "    config = ConfigurationManager()  # Initialize configuration manager\n",
    "    data_validation_config = config.get_data_validation_config()  # Fetch data validation config\n",
    "    data_validation = DataValidation(config=data_validation_config)  # Create DataValidation instance\n",
    "    data_validation.validation_all_columns()  # Perform validation\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yt_video_sum",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
